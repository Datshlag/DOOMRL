{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# E. Culurciello\n",
    "# August 2017\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from vizdoom import *\n",
    "import itertools as it\n",
    "from random import sample, randint, random\n",
    "from time import time, sleep\n",
    "import numpy as np\n",
    "import skimage.color, skimage.transform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q-learning settings\n",
    "learning_rate = 0.00025\n",
    "discount_factor = 0.99\n",
    "epochs = 20\n",
    "learning_steps_per_epoch = 2000\n",
    "replay_memory_size = 1000\n",
    "\n",
    "# NN learning settings\n",
    "batch_size = 64\n",
    "\n",
    "# Training regime\n",
    "test_episodes_per_epoch = 100\n",
    "\n",
    "# Other parameters\n",
    "frame_repeat = 12\n",
    "resolution = (30, 45)\n",
    "episodes_to_watch = 10\n",
    "\n",
    "model_savefile = \"./models/dqn_simple.pth\"\n",
    "save_model = False\n",
    "load_model = True\n",
    "skip_learning = False\n",
    "\n",
    "# Configuration file path\n",
    "# config_file_path = \"ViZDoom/scenarios/basic.cfg\"\n",
    "config_file_path = \"ViZDoom/scenarios/rocket_basic.cfg\"\n",
    "# config_file_path = \"../../scenarios/basic.cfg\"\n",
    "\n",
    "# Converts and down-samples the input image\n",
    "def preprocess(img):\n",
    "    img = skimage.transform.resize(img, resolution)\n",
    "    img = img.astype(np.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        channels = 1\n",
    "        state_shape = (capacity, channels, resolution[0], resolution[1])\n",
    "        self.s1 = np.zeros(state_shape, dtype=np.float32)\n",
    "        self.s2 = np.zeros(state_shape, dtype=np.float32)\n",
    "        self.a = np.zeros(capacity, dtype=np.int32)\n",
    "        self.r = np.zeros(capacity, dtype=np.float32)\n",
    "        self.isterminal = np.zeros(capacity, dtype=np.float32)\n",
    "\n",
    "        self.capacity = capacity\n",
    "        self.size = 0\n",
    "        self.pos = 0\n",
    "\n",
    "    def add_transition(self, s1, action, s2, isterminal, reward):\n",
    "        self.s1[self.pos, 0, :, :] = s1\n",
    "        self.a[self.pos] = action\n",
    "        if not isterminal:\n",
    "            self.s2[self.pos, 0, :, :] = s2\n",
    "        self.isterminal[self.pos] = isterminal\n",
    "        self.r[self.pos] = reward\n",
    "\n",
    "        self.pos = (self.pos + 1) % self.capacity\n",
    "        self.size = min(self.size + 1, self.capacity)\n",
    "\n",
    "    def get_sample(self, sample_size):\n",
    "        i = sample(range(0, self.size), sample_size)\n",
    "        return self.s1[i], self.a[i], self.s2[i], self.isterminal[i], self.r[i]\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, available_actions_count):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=6, stride=3)\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(192, 128)\n",
    "        self.fc2 = nn.Linear(128, available_actions_count)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 192)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "def learn(s1, target_q):\n",
    "    s1 = torch.from_numpy(s1)\n",
    "    target_q = torch.from_numpy(target_q)\n",
    "    s1, target_q = Variable(s1), Variable(target_q)\n",
    "    output = model(s1)\n",
    "    loss = criterion(output, target_q)\n",
    "    # compute gradient and do SGD step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def get_q_values(state):\n",
    "    state = torch.from_numpy(state)\n",
    "    state = Variable(state)\n",
    "    return model(state)\n",
    "\n",
    "def get_best_action(state):\n",
    "    q = get_q_values(state)\n",
    "    m, index = torch.max(q, 1)\n",
    "    action = index.data.numpy()[0]\n",
    "    return action\n",
    "\n",
    "\n",
    "def learn_from_memory():\n",
    "    \"\"\" Learns from a single transition (making use of replay memory).\n",
    "    s2 is ignored if s2_isterminal \"\"\"\n",
    "\n",
    "    # Get a random minibatch from the replay memory and learns from it.\n",
    "    if memory.size > batch_size:\n",
    "        s1, a, s2, isterminal, r = memory.get_sample(batch_size)\n",
    "\n",
    "        q = get_q_values(s2).data.numpy()\n",
    "        q2 = np.max(q, axis=1)\n",
    "        target_q = get_q_values(s1).data.numpy()\n",
    "        # target differs from q only for the selected action. The following means:\n",
    "        # target_Q(s,a) = r + gamma * max Q(s2,_) if isterminal else r\n",
    "        target_q[np.arange(target_q.shape[0]), a] = r + discount_factor * (1 - isterminal) * q2\n",
    "        learn(s1, target_q)\n",
    "\n",
    "\n",
    "def perform_learning_step(epoch):\n",
    "    \"\"\" Makes an action according to eps-greedy policy, observes the result\n",
    "    (next state, reward) and learns from the transition\"\"\"\n",
    "\n",
    "    def exploration_rate(epoch):\n",
    "        \"\"\"# Define exploration rate change over time\"\"\"\n",
    "        start_eps = 1.0\n",
    "        end_eps = 0.1\n",
    "        const_eps_epochs = 0.1 * epochs  # 10% of learning time\n",
    "        eps_decay_epochs = 0.6 * epochs  # 60% of learning time\n",
    "\n",
    "        if epoch < const_eps_epochs:\n",
    "            return start_eps\n",
    "        elif epoch < eps_decay_epochs:\n",
    "            # Linear decay\n",
    "            return start_eps - (epoch - const_eps_epochs) / \\\n",
    "                               (eps_decay_epochs - const_eps_epochs) * (start_eps - end_eps)\n",
    "        else:\n",
    "            return end_eps\n",
    "\n",
    "    s1 = preprocess(game.get_state().screen_buffer)\n",
    "\n",
    "    # With probability eps make a random action.\n",
    "    eps = exploration_rate(epoch)\n",
    "    if random() <= eps:\n",
    "        a = randint(0, len(actions) - 1)\n",
    "    else:\n",
    "        # Choose the best action according to the network.\n",
    "        s1 = s1.reshape([1, 1, resolution[0], resolution[1]])\n",
    "        a = get_best_action(s1)\n",
    "    reward = game.make_action(actions[a], frame_repeat)\n",
    "\n",
    "    isterminal = game.is_episode_finished()\n",
    "    s2 = preprocess(game.get_state().screen_buffer) if not isterminal else None\n",
    "\n",
    "    # Remember the transition that was just experienced.\n",
    "    memory.add_transition(s1, a, s2, isterminal, reward)\n",
    "\n",
    "    learn_from_memory()\n",
    "\n",
    "\n",
    "# Creates and initializes ViZDoom environment.\n",
    "def initialize_vizdoom(config_file_path):\n",
    "    print(\"Initializing doom...\")\n",
    "    game = DoomGame()\n",
    "    game.load_config(config_file_path)\n",
    "    game.set_window_visible(False)\n",
    "    game.set_mode(Mode.PLAYER)\n",
    "    game.set_screen_format(ScreenFormat.GRAY8)\n",
    "    game.set_screen_resolution(ScreenResolution.RES_640X480)\n",
    "    game.init()\n",
    "    print(\"Doom initialized.\")\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing doom...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]/home/alois/.conda/envs/mva/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "  0%|          | 6/2000 [00:00<00:33, 59.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doom initialized.\n",
      "Loading model from:  ./models/dqn_simple.pth\n",
      "Starting the training!\n",
      "\n",
      "Epoch 1\n",
      "-------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 training episodes played.\n",
      "Results: mean: -215.6 +/- 160.2, min: -360.0, max: 66.0,\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alois/.conda/envs/mva/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "  0%|          | 3/2000 [00:00<01:07, 29.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: mean: 24.9 +/- 86.3, min: -300.0 max: 66.0\n",
      "Saving the network weigths to: ./models/dqn_simple.pth\n",
      "Total elapsed time: 1.14 minutes\n",
      "\n",
      "Epoch 2\n",
      "-------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:11,  8.67it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 training episodes played.\n",
      "Results: mean: -155.6 +/- 161.0, min: -360.0, max: 66.0,\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:00<00:58, 33.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: mean: 21.7 +/- 88.3, min: -300.0 max: 66.0\n",
      "Saving the network weigths to: ./models/dqn_simple.pth\n",
      "Total elapsed time: 2.31 minutes\n",
      "\n",
      "Epoch 3\n",
      "-------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:00<00:05, 16.87it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 training episodes played.\n",
      "Results: mean: -177.1 +/- 161.3, min: -360.0, max: 66.0,\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:00<00:59, 33.68it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: mean: 36.4 +/- 50.5, min: -135.0 max: 66.0\n",
      "Saving the network weigths to: ./models/dqn_simple.pth\n",
      "Total elapsed time: 3.47 minutes\n",
      "\n",
      "Epoch 4\n",
      "-------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:04, 23.24it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 training episodes played.\n",
      "Results: mean: -122.5 +/- 157.8, min: -365.0, max: 66.0,\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:00<01:02, 32.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: mean: 52.4 +/- 19.0, min: -17.0 max: 66.0\n",
      "Saving the network weigths to: ./models/dqn_simple.pth\n",
      "Total elapsed time: 4.60 minutes\n",
      "\n",
      "Epoch 5\n",
      "-------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:04, 22.43it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 training episodes played.\n",
      "Results: mean: -83.6 +/- 139.3, min: -360.0, max: 66.0,\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:00<00:53, 37.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: mean: 45.2 +/- 34.6, min: -95.0 max: 66.0\n",
      "Saving the network weigths to: ./models/dqn_simple.pth\n",
      "Total elapsed time: 5.76 minutes\n",
      "\n",
      "Epoch 6\n",
      "-------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:00<00:05, 18.37it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 training episodes played.\n",
      "Results: mean: -43.3 +/- 110.5, min: -365.0, max: 66.0,\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:00<00:58, 33.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: mean: 20.5 +/- 91.9, min: -300.0 max: 66.0\n",
      "Saving the network weigths to: ./models/dqn_simple.pth\n",
      "Total elapsed time: 6.95 minutes\n",
      "\n",
      "Epoch 7\n",
      "-------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1118/2000 [00:37<00:29, 29.61it/s]"
     ]
    },
    {
     "ename": "SignalException",
     "evalue": "Signal SIGINT received. ViZDoom instance has been closed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSignalException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1abe02e4db9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlearning_step\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_steps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mperform_learning_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_episode_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_total_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6d4dc8843e37>\u001b[0m in \u001b[0;36mperform_learning_step\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0misterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_episode_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSignalException\u001b[0m: Signal SIGINT received. ViZDoom instance has been closed."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 1118/2000 [00:50<00:39, 22.34it/s]"
     ]
    }
   ],
   "source": [
    "# Create Doom instance\n",
    "game = initialize_vizdoom(config_file_path)\n",
    "\n",
    "# Action = which buttons are pressed\n",
    "n = game.get_available_buttons_size()\n",
    "actions = [list(a) for a in it.product([0, 1], repeat=n)]\n",
    "\n",
    "# Create replay memory which will store the transitions\n",
    "memory = ReplayMemory(capacity=replay_memory_size)\n",
    "\n",
    "if load_model:\n",
    "    print(\"Loading model from: \", model_savefile)\n",
    "    model = torch.load(model_savefile)\n",
    "else:\n",
    "    model = Net(len(actions))\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "print(\"Starting the training!\")\n",
    "time_start = time()\n",
    "if not skip_learning:\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\\nEpoch %d\\n-------\" % (epoch + 1))\n",
    "        train_episodes_finished = 0\n",
    "        train_scores = []\n",
    "\n",
    "        print(\"Training...\")\n",
    "        game.new_episode()\n",
    "        for learning_step in trange(learning_steps_per_epoch, leave=False):\n",
    "            perform_learning_step(epoch)\n",
    "            if game.is_episode_finished():\n",
    "                score = game.get_total_reward()\n",
    "                train_scores.append(score)\n",
    "                game.new_episode()\n",
    "                train_episodes_finished += 1\n",
    "\n",
    "        print(\"%d training episodes played.\" % train_episodes_finished)\n",
    "\n",
    "        train_scores = np.array(train_scores)\n",
    "\n",
    "        print(\"Results: mean: %.1f +/- %.1f,\" % (train_scores.mean(), train_scores.std()), \\\n",
    "              \"min: %.1f,\" % train_scores.min(), \"max: %.1f,\" % train_scores.max())\n",
    "\n",
    "        print(\"\\nTesting...\")\n",
    "        test_episode = []\n",
    "        test_scores = []\n",
    "        for test_episode in trange(test_episodes_per_epoch, leave=False):\n",
    "            game.new_episode()\n",
    "            while not game.is_episode_finished():\n",
    "                state = preprocess(game.get_state().screen_buffer)\n",
    "                state = state.reshape([1, 1, resolution[0], resolution[1]])\n",
    "                best_action_index = get_best_action(state)\n",
    "\n",
    "                game.make_action(actions[best_action_index], frame_repeat)\n",
    "            r = game.get_total_reward()\n",
    "            test_scores.append(r)\n",
    "\n",
    "        test_scores = np.array(test_scores)\n",
    "        print(\"Results: mean: %.1f +/- %.1f,\" % (\n",
    "            test_scores.mean(), test_scores.std()), \"min: %.1f\" % test_scores.min(),\n",
    "              \"max: %.1f\" % test_scores.max())\n",
    "\n",
    "        print(\"Saving the network weigths to:\", model_savefile)\n",
    "        torch.save(model, model_savefile)\n",
    "\n",
    "        print(\"Total elapsed time: %.2f minutes\" % ((time() - time_start) / 60.0))\n",
    "\n",
    "game.close()\n",
    "print(\"======================================\")\n",
    "print(\"Training finished. It's time to watch!\")\n",
    "\n",
    "# Reinitialize the game with window visible\n",
    "game.set_window_visible(True)\n",
    "game.set_mode(Mode.ASYNC_PLAYER)\n",
    "game.init()\n",
    "\n",
    "for _ in range(episodes_to_watch):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        state = preprocess(game.get_state().screen_buffer)\n",
    "        state = state.reshape([1, 1, resolution[0], resolution[1]])\n",
    "        best_action_index = get_best_action(state)\n",
    "\n",
    "        # Instead of make_action(a, frame_repeat) in order to make the animation smooth\n",
    "        game.set_action(actions[best_action_index])\n",
    "        for _ in range(frame_repeat):\n",
    "            game.advance_action()\n",
    "\n",
    "    # Sleep between episodes\n",
    "    sleep(1.0)\n",
    "    score = game.get_total_reward()\n",
    "    print(\"Total score: \", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
